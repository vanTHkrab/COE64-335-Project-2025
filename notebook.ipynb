{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/vanTHkrab/COE64-335-Project-2025/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "14865fccf660e157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell.\n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "755f63be450eee97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "import joblib\n",
    "\n"
   ],
   "id": "678dd8352dc38f10",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv(\"data/raw-rain-data.csv\")",
   "id": "e29efe8627be8e75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "7358ef5db6ef1b6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Cleaning",
   "id": "aa8d029d00d7f362"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1. Check Missing value",
   "id": "96bc628c71ab28da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "print(df.describe(include=\"all\"))"
   ],
   "id": "79cb14d76e5bf206",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2.ตัด Column PROV_ID",
   "id": "a81e1172d188dff0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns=[\"PROV_T\"])\n",
   "id": "23c0717b335f836a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "10b764238f096dcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3.สร้าง Label >= 90 คือตก",
   "id": "8231eac90e8fe3d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"Rain\"] = (df[\"AvgRain\"] >= 90).astype(int)",
   "id": "885ea8f8b62e752e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "3d9f3d8d42ceba51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature Engineering",
   "id": "8fb48a2ae108d7ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "1.Add coulumn",
   "id": "dbde170becba1a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- Seasonality",
   "id": "4bb74bd1a37f8d92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"month_sin\"] = np.sin(2*np.pi*df[\"MONTH\"]/12)\n",
    "df[\"month_cos\"] = np.cos(2*np.pi*df[\"MONTH\"]/12)"
   ],
   "id": "9985b4953ed13555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(5)",
   "id": "ad79f77b1f4c8d6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns=[\"MONTH\"])",
   "id": "b4f31833cea26a5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head(3)",
   "id": "f6a30156120899f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train/Test Split",
   "id": "ac21aea137220cdf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = df[[\"PROV_ID\", \"month_sin\", \"month_cos\"]]\n",
    "y = df[\"Rain\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ],
   "id": "98c658858f50e65d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"X_train sample:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\ny_train sample:\")\n",
    "print(y_train.head())\n",
    "\n",
    "print(\"\\nX_test sample:\")\n",
    "print(X_test.head())\n",
    "\n",
    "print(\"\\ny_test sample:\")\n",
    "print(y_test.head())\n"
   ],
   "id": "9ee873715ffa83e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7bfd7ed3e5417bc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "781f748fc803ff10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "65af968459f64014",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8db9730f85478c9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2fc47e2cd3686ace"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d855ca08d8d7201b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "38dc9fb2907680ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "********** Traning ************\n",
    "and scaling"
   ],
   "id": "834430693e236911"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Logistic Regression",
   "id": "ed49b8d06fb12c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# log_pipe = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"clf\", LogisticRegression(max_iter=1000))\n",
    "# ])\n",
    "# log_pipe.fit(X_train, y_train)"
   ],
   "id": "8ab5209272548a79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# y_pred = log_pipe.predict(X_test)\n",
    "# y_proba = log_pipe.predict_proba(X_test)[:, 1]   # ใช้ proba ของ Rain=1\n",
    "#\n",
    "# print(\"=== Logistic Regression ===\")\n",
    "# print(classification_report(y_test, y_pred, digits=4))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "#\n",
    "# # เพิ่ม F1 และ ROC-AUC\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# auc = roc_auc_score(y_test, y_proba)\n",
    "# print(f\"F1-score (test): {f1:.4f}\")\n",
    "# print(f\"ROC-AUC   (test): {auc:.4f}\")"
   ],
   "id": "dd6eb99d53b55466",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Decision Tree",
   "id": "bdeec93aa012b1f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# tree_pipe = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),   # จริง ๆ ไม่จำเป็นกับ tree\n",
    "#     (\"clf\", DecisionTreeClassifier(random_state=42))\n",
    "# ])\n",
    "# tree_pipe.fit(X_train, y_train)"
   ],
   "id": "830c8566fa708a64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# y_pred = tree_pipe.predict(X_test)\n",
    "# print(\"=== Decision Tree ===\")\n",
    "# print(classification_report(y_test, y_pred, digits=4))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# # เพิ่ม F1 และ ROC-AUC\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# auc = roc_auc_score(y_test, y_proba)\n",
    "# print(f\"F1-score (test): {f1:.4f}\")\n",
    "# print(f\"ROC-AUC   (test): {auc:.4f}\")"
   ],
   "id": "d21ada89ca729e8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest",
   "id": "77e18e8c537d529c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rf_pipe = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),   # ไม่จำเป็นกับ forest เช่นกัน\n",
    "#     (\"clf\", RandomForestClassifier(random_state=42))\n",
    "# ])\n",
    "# rf_pipe.fit(X_train, y_train)"
   ],
   "id": "c008dd0c86f9d707",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# y_pred = rf_pipe.predict(X_test)\n",
    "# print(\"=== Random Forest ===\")\n",
    "# print(classification_report(y_test, y_pred, digits=4))\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# # เพิ่ม F1 และ ROC-AUC\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# auc = roc_auc_score(y_test, y_proba)\n",
    "# print(f\"F1-score (test): {f1:.4f}\")\n",
    "# print(f\"ROC-AUC   (test): {auc:.4f}\")"
   ],
   "id": "3d286ddb79548c80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "30b9f1b6a3674a53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2421ffd280c3746c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b908e42ac475d39e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "21f70b517eee2816"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameter Tunning",
   "id": "cf2780fa82b1717"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Grid Search",
   "id": "fa034a37527f4629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix, make_scorer,\n",
    "    balanced_accuracy_score\n",
    ")\n",
    "\n",
    "# ใช้ร่วมกับ:\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# scoring = \"f1\"   # (ยังใช้ได้) แต่ในฟังก์ชันนี้จะสร้าง scorers หลายตัวให้อัตโนมัติ\n",
    "\n",
    "def _get_proba_or_decision(estimator, X) -> np.ndarray:\n",
    "    \"\"\"คืนค่า 'ความน่าจะเป็นของ positive class' (binary) หรือ 'matrix proba' (multiclass)\n",
    "       ถ้าไม่มี predict_proba จะ fallback เป็น decision_function และสเกลให้อยู่ [0,1] แบบ min-max\"\"\"\n",
    "    if hasattr(estimator, \"predict_proba\"):\n",
    "        proba = estimator.predict_proba(X)\n",
    "        return proba\n",
    "    elif hasattr(estimator, \"decision_function\"):\n",
    "        dec = estimator.decision_function(X)\n",
    "        # binary: (n,), multiclass: (n, n_classes)\n",
    "        if dec.ndim == 1:\n",
    "            dec = dec.reshape(-1, 1)\n",
    "        # min-max per column\n",
    "        dmin = dec.min(axis=0, keepdims=True)\n",
    "        dmax = dec.max(axis=0, keepdims=True)\n",
    "        rng = np.clip(dmax - dmin, 1e-12, None)\n",
    "        p = (dec - dmin) / rng\n",
    "        # ถ้า binary จะได้คอลัมน์เดียว ให้รวมเป็น 2 คอลัมน์ [1-p, p] เพื่อความสอดคล้อง\n",
    "        if p.shape[1] == 1:\n",
    "            p = np.hstack([1 - p, p])\n",
    "        return p\n",
    "    else:\n",
    "        # ไม่มีทั้งสองอย่าง → ใช้ predict แล้ว cast เป็น proba (จำเป็นจริง ๆ เท่านั้น)\n",
    "        pred = estimator.predict(X)\n",
    "        # one-hot dummy\n",
    "        classes = np.unique(pred)\n",
    "        n_classes = classes.size\n",
    "        out = np.zeros((pred.shape[0], n_classes))\n",
    "        for i, c in enumerate(classes):\n",
    "            out[:, i] = (pred == c).astype(float)\n",
    "        # ถ้าเป็น binary แปลงให้คอลัมน์ 1 คือ positive (assume class 1 ถ้ามี)\n",
    "        if n_classes == 1:\n",
    "            out = np.hstack([1 - out, out])\n",
    "        return out\n",
    "\n",
    "def _best_threshold_by_f1(y_true: np.ndarray, pos_score: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"สแกน threshold 200 จุด หา threshold ที่ให้ F1 สูงสุด (binary)\"\"\"\n",
    "    thresh_grid = np.linspace(0.0, 1.0, 201)\n",
    "    best_f1, best_t = -1.0, 0.5\n",
    "    for t in thresh_grid:\n",
    "        y_hat = (pos_score >= t).astype(int)\n",
    "        f1 = f1_score(y_true, y_hat, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    return best_t, best_f1\n",
    "\n",
    "def run_grid_search(\n",
    "    pipe,\n",
    "    grid,\n",
    "    *,\n",
    "    cv=None,\n",
    "    primary_metric: str = \"f1\",      # metric ที่จะใช้ refit\n",
    "    tune_threshold: bool = True,     # ถ้าเป็น binary จะจูน threshold บน val split\n",
    "    show_top_k: int = 10,            # แสดง top-k แถวแรกของ cv_results_\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    # ===== 1) CV & scorers =====\n",
    "    if cv is None:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # สร้าง scorers หลายตัวเพื่อดูภาพรวม\n",
    "    scorers: Dict[str, Any] = {\n",
    "        \"f1\": make_scorer(f1_score),\n",
    "        \"f1_macro\": \"f1_macro\",\n",
    "        \"f1_weighted\": \"f1_weighted\",\n",
    "        \"balanced_acc\": make_scorer(balanced_accuracy_score),\n",
    "        # หมายเหตุ: roc_auc จะใช้ได้ดีใน binary; ถ้าเป็น multiclass ใช้ roc_auc_ovr/ovo\n",
    "        \"roc_auc\": \"roc_auc\",\n",
    "        \"roc_auc_ovr\": \"roc_auc_ovr\",\n",
    "        \"ap\": \"average_precision\",  # PR-AUC (binary)\n",
    "    }\n",
    "\n",
    "    # ===== 2) GridSearchCV (error_score=\"nan\" จะข้ามคอมโบที่ไม่เข้ากัน) =====\n",
    "    search = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=grid,\n",
    "        scoring=scorers,\n",
    "        refit=primary_metric,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        error_score=np.nan,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "    search.fit(X_train, y_train)  # อาศัยตัวแปร global เหมือนโค้ดเดิมของคุณ\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "    print(\"\\n[Best params]\")\n",
    "    print(search.best_params_)\n",
    "    print(f\"[Best CV {primary_metric}]: {search.best_score_:.6f}\")\n",
    "\n",
    "    # ===== 3) แสดงผล CV top-k =====\n",
    "    cv_df = pd.DataFrame(search.cv_results_)\n",
    "    rank_col = f\"rank_test_{primary_metric}\"\n",
    "    score_col = f\"mean_test_{primary_metric}\"\n",
    "    cols = [rank_col, score_col] + [c for c in cv_df.columns if c.startswith(\"param_\")]\n",
    "    cv_view = cv_df.sort_values(rank_col)[cols].head(show_top_k)\n",
    "    print(f\"\\n[Top {show_top_k} by {primary_metric}]\")\n",
    "    print(cv_view.to_string(index=False))\n",
    "\n",
    "    # ===== 4) ประเมินบน test set + (ออปชัน) ปรับ threshold สำหรับ binary =====\n",
    "    y_pred_default = best_model.predict(X_test)\n",
    "\n",
    "    # เตรียมคะแนน/โปรบาบิลิตี\n",
    "    proba_test = _get_proba_or_decision(best_model, X_test)\n",
    "    n_classes = proba_test.shape[1]\n",
    "    is_binary = (n_classes == 2)\n",
    "\n",
    "    if is_binary:\n",
    "        pos_proba_test = proba_test[:, 1]\n",
    "\n",
    "        # default (threshold = 0.5)\n",
    "        f1_default = f1_score(y_test, y_pred_default)\n",
    "        auc_roc = roc_auc_score(y_test, pos_proba_test)\n",
    "        ap = average_precision_score(y_test, pos_proba_test)\n",
    "\n",
    "        if tune_threshold:\n",
    "            # split train → (sub-train, val) เพื่อหา threshold ที่ให้ F1 ดีสุด\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=random_state)\n",
    "            (tr_idx, val_idx), = sss.split(X_train, y_train)\n",
    "            # ฟิตใหม่บน sub-train เพื่อป้องกันข้อมูลรั่ว (หรือจะใช้ best_model เดิมบน X_train ก็ได้ แต่เข้มงวดหน่อย)\n",
    "            best_model.fit(X_train[tr_idx], y_train[tr_idx])\n",
    "            proba_val = _get_proba_or_decision(best_model, X_train[val_idx])[:, 1]\n",
    "            t_star, val_f1 = _best_threshold_by_f1(y_train[val_idx], proba_val)\n",
    "\n",
    "            # ประเมินบน test ด้วย threshold ใหม่\n",
    "            proba_test_star = _get_proba_or_decision(best_model, X_test)[:, 1]\n",
    "            y_pred_star = (proba_test_star >= t_star).astype(int)\n",
    "            f1_star = f1_score(y_test, y_pred_star)\n",
    "\n",
    "            print(\"\\n[Test metrics (binary)]\")\n",
    "            print(f\" F1 (default 0.5): {f1_default:.4f}\")\n",
    "            print(f\" F1 (tuned @ {t_star:.3f}): {f1_star:.4f}  [val-F1={val_f1:.4f}]\")\n",
    "            print(f\" ROC-AUC: {auc_roc:.4f}\")\n",
    "            print(f\" PR-AUC (AP): {ap:.4f}\")\n",
    "\n",
    "            # สรุปรีพอร์ต/คอนฟิวชันแมทริกซ์ด้วย threshold ที่ดีกว่า\n",
    "            y_pred = y_pred_star if f1_star >= f1_default else y_pred_default\n",
    "        else:\n",
    "            print(\"\\n[Test metrics (binary)]\")\n",
    "            print(f\" F1: {f1_default:.4f}\")\n",
    "            print(f\" ROC-AUC: {auc_roc:.4f}\")\n",
    "            print(f\" PR-AUC (AP): {ap:.4f}\")\n",
    "            y_pred = y_pred_default\n",
    "\n",
    "    else:\n",
    "        # multiclass\n",
    "        y_pred = y_pred_default\n",
    "        print(\"\\n[Test metrics (multiclass)]\")\n",
    "        print(f\" F1-macro: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "        print(f\" F1-weighted: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
    "        # ovr AUC (ต้องการ proba/score ทุกรุ่น)\n",
    "        try:\n",
    "            auc_ovr = roc_auc_score(y_test, proba_test, multi_class=\"ovr\")\n",
    "            print(f\" ROC-AUC (OvR): {auc_ovr:.4f}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ===== 5) รายงานละเอียด =====\n",
    "    print(\"\\n[Classification report]\")\n",
    "    print(classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"[Confusion matrix]\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # ส่งคืนทั้งโมเดลและตารางผล CV เผื่อคุณอยากเก็บลงไฟล์/วิเคราะห์ต่อ\n",
    "    return best_model, cv_df\n"
   ],
   "id": "ed11cc9ebfbb8ad9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### - Logistic Regession",
   "id": "3ea26ba8aeb6a846"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(max_iter=4000, multi_class=\"auto\"))\n",
    "])"
   ],
   "id": "e3da0112a0ba2a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# grid_lr = [\n",
    "#     {\n",
    "#         \"clf__solver\": [\"lbfgs\", \"newton-cg\", \"liblinear\"],\n",
    "#         \"clf__penalty\": [\"l2\", \"none\"] if \"liblinear\" not in [\"liblinear\"] else [\"l2\"],  # อธิบายด้านล่าง\n",
    "#         \"clf__C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 100.0],\n",
    "#         \"clf__class_weight\": [None, \"balanced\"],\n",
    "#         \"clf__fit_intercept\": [True, False],\n",
    "#         \"clf__tol\": [1e-4, 1e-5],\n",
    "#     },\n",
    "#     {\n",
    "#         \"clf__solver\": [\"liblinear\"],\n",
    "#         \"clf__penalty\": [\"l1\", \"l2\"],   # liblinear รองรับ L1 ด้วย\n",
    "#         \"clf__C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 100.0],\n",
    "#         \"clf__class_weight\": [None, \"balanced\"],\n",
    "#         \"clf__fit_intercept\": [True, False],\n",
    "#         \"clf__tol\": [1e-4, 1e-5],\n",
    "#     },\n",
    "#     {\n",
    "#         \"clf__solver\": [\"saga\"],\n",
    "#         \"clf__penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "#         \"clf__l1_ratio\": [0.1, 0.5, 0.9],  # ใช้เมื่อ penalty=\"elasticnet\"\n",
    "#         \"clf__C\": [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0, 100.0],\n",
    "#         \"clf__class_weight\": [None, \"balanced\"],\n",
    "#         \"clf__fit_intercept\": [True, False],\n",
    "#         \"clf__tol\": [1e-4, 1e-5],\n",
    "#     },\n",
    "# ]\n",
    "#\n",
    "# best_lr = run_grid_search(lr_pipe, grid_lr)"
   ],
   "id": "2430eddef39b3c24",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# lr_pipe = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"clf\", LogisticRegression(max_iter=4000, solver=\"lbfgs\"))\n",
    "# ])\n",
    "#\n",
    "# grid_lr = {\n",
    "#     \"clf__C\": [0.1, 0.5, 1.0, 2.0, 10.0],   # คุมความแรง regularization\n",
    "#     \"clf__class_weight\": [None, \"balanced\"] # ถ่วง class ถ้า skew\n",
    "# }\n",
    "#\n",
    "#\n",
    "# best_lr = run_grid_search(lr_pipe, grid_lr)\n"
   ],
   "id": "7020d4cca6b85da5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ใช้กับ Pipeline ที่ตั้งชื่อ estimator ว่า 'clf' (เช่น lr_pipe = Pipeline([... , ('clf', LogisticRegression())]))\n",
    "\n",
    "grid_lr_long = [\n",
    "    # ===== lbfgs / newton-cg / sag: รองรับเฉพาะ L2 และ none =====\n",
    "    {\n",
    "        \"clf__solver\": [\"lbfgs\", \"newton-cg\", \"sag\"],\n",
    "        \"clf__penalty\": [\"l2\", \"none\"],\n",
    "        \"clf__C\": [1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 0.05, 0.1, 0.2, 0.5,\n",
    "                   1, 2, 5, 10, 20, 50, 100, 200, 500, 1_000, 5_000],\n",
    "        \"clf__tol\": [1e-2, 3e-3, 1e-3, 3e-4, 1e-4, 3e-5, 1e-5, 1e-6],\n",
    "        \"clf__max_iter\": [100, 200, 500, 1_000, 2_000, 5_000],\n",
    "        \"clf__fit_intercept\": [True, False],\n",
    "        \"clf__class_weight\": [None, \"balanced\"],\n",
    "        \"clf__multi_class\": [\"auto\", \"ovr\", \"multinomial\"],\n",
    "        # sag มักไวกับ learning conditions; ให้ลองทั้งสามตัวรวมกันเพื่อเปรียบเทียบ\n",
    "        \"clf__warm_start\": [False, True],\n",
    "    },\n",
    "\n",
    "    # ===== liblinear: รองรับ L1/L2, ใช้ ovr เท่านั้น; dual ใช้กับ L2 เท่านั้น =====\n",
    "    {\n",
    "        \"clf__solver\": [\"liblinear\"],\n",
    "        \"clf__penalty\": [\"l1\", \"l2\"],\n",
    "        \"clf__dual\": [False, True],          # จะถูกใช้เฉพาะคู่กับ penalty='l2'\n",
    "        \"clf__intercept_scaling\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "        \"clf__C\": [1e-5, 1e-4, 1e-3, 1e-2, 0.05, 0.1, 0.2, 0.5,\n",
    "                   1, 2, 5, 10, 20, 50, 100, 200, 500, 1_000, 2_000],\n",
    "        \"clf__tol\": [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "        \"clf__max_iter\": [100, 200, 500, 1_000, 2_000],\n",
    "        \"clf__fit_intercept\": [True, False],\n",
    "        \"clf__class_weight\": [None, \"balanced\"],\n",
    "        \"clf__multi_class\": [\"ovr\"],\n",
    "        \"clf__warm_start\": [False, True],\n",
    "    },\n",
    "\n",
    "    # ===== saga: รองรับ L1/L2/elasticnet, รองรับ multinomial =====\n",
    "    {\n",
    "        \"clf__solver\": [\"saga\"],\n",
    "        \"clf__penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"clf__l1_ratio\": [0.0, 0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 0.9, 1.0],  # ใช้เมื่อ penalty='elasticnet'\n",
    "        \"clf__C\": [1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 0.05, 0.1, 0.2, 0.5,\n",
    "                   1, 2, 5, 10, 20, 50, 100, 200, 500, 1_000, 2_000, 5_000],\n",
    "        \"clf__tol\": [1e-2, 3e-3, 1e-3, 3e-4, 1e-4, 3e-5, 1e-5, 1e-6],\n",
    "        \"clf__max_iter\": [200, 500, 1_000, 2_000, 5_000, 10_000],\n",
    "        \"clf__fit_intercept\": [True, False],\n",
    "        \"clf__class_weight\": [None, \"balanced\"],\n",
    "        \"clf__multi_class\": [\"auto\", \"ovr\", \"multinomial\"],\n",
    "        \"clf__warm_start\": [False, True],\n",
    "    },\n",
    "]\n",
    "\n",
    "best_lr = run_grid_search(lr_pipe, grid_lr_long)\n",
    "joblib.dump(best_lr, 'models/best_lr_model.joblib')"
   ],
   "id": "250dbeeef82da49d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### - Decision Tree",
   "id": "c71e6cd5c4261e8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dt_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "grid_dt = {\n",
    "    \"clf__max_depth\": [None, 5, 10, 15],  # กัน overfit\n",
    "    \"clf__min_samples_leaf\": [1, 3, 5, 10],\n",
    "    \"clf__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "best_dt = run_grid_search(dt_pipe, grid_dt)\n"
   ],
   "id": "55cec86cf8db371b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### - Random Forest",
   "id": "e74ea163d2f009d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "grid_rf = {\n",
    "    \"clf__n_estimators\": [200, 400, 600],  # มากขึ้น = เสถียรขึ้น (แต่ช้าขึ้น)\n",
    "    \"clf__max_depth\": [None, 10, 15, 20],\n",
    "    \"clf__min_samples_leaf\": [1, 2, 4],\n",
    "    \"clf__max_features\": [\"sqrt\", \"log2\"], # 'sqrt' มักดีสำหรับ classification\n",
    "    \"clf__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "best_rf = run_grid_search(rf_pipe, grid_rf)\n"
   ],
   "id": "1f44361518379288",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# rf_pipe = Pipeline([\n",
    "#     (\"scaler\", StandardScaler()),\n",
    "#     (\"clf\", RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "# ])\n",
    "#\n",
    "# grid_rf = {\n",
    "#     # จำนวนต้นไม้ (เยอะขึ้น เสถียรขึ้น แต่ช้าลง)\n",
    "#     \"clf__n_estimators\": [200, 400, 600, 1000],\n",
    "#\n",
    "#     # ความลึกของต้นไม้\n",
    "#     \"clf__max_depth\": [None, 10, 15, 25, 30],\n",
    "#\n",
    "#     # จำนวน sample ขั้นต่ำต่อ split และ leaf\n",
    "#     \"clf__min_samples_split\": [2, 5, 10],\n",
    "#     \"clf__min_samples_leaf\": [1, 2, 6],\n",
    "#\n",
    "#     # ฟีเจอร์ที่ใช้ตอน split\n",
    "#     \"clf__max_features\": [\"sqrt\", \"log2\", None],\n",
    "#\n",
    "#     # ถ่วงน้ำหนักคลาส\n",
    "#     \"clf__class_weight\": [None, \"balanced\"]\n",
    "# }\n",
    "#\n",
    "# best_rf = run_grid_search(rf_pipe, grid_rf)\n",
    "#\n",
    "# # Export the trained RandomForest model\n",
    "# joblib.dump(best_rf, 'models/best_rf_model.joblib')\n",
    "# print('Model exported to models/best_rf_model.joblib')\n"
   ],
   "id": "276ea8ff90c8702",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Pipeline: เพิ่ม PCA คั่นกลางเพื่อเพิ่มมิติการค้นหา\n",
    "lr_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(random_state=0)),             # ใส่ PCA เสมอ แต่กำหนด n_components ผ่านกริด\n",
    "    (\"clf\", LogisticRegression(solver=\"lbfgs\"))\n",
    "])\n",
    "\n",
    "# กริดขยายใหญ่ (~13,824 combinations)\n",
    "grid_lr = {\n",
    "    # ----- PCA (6 คอมโบ) -----\n",
    "    # None = ไม่ลดมิติ (ยังคงคำนวณ PCA อยู่ → ช่วยเพิ่มเวลา), 0.95/0.99 = คงความแปรปรวนตามสัดส่วน\n",
    "    \"pca__n_components\": [None, 0.95, 0.99],\n",
    "    \"pca__whiten\": [True, False],             # ทำให้คอมโบเพิ่มขึ้นและช้าขึ้นเล็กน้อย\n",
    "    # (คง svd_solver เป็น \"auto\" เพื่อเลี่ยงคอมโบเสี่ยง)\n",
    "\n",
    "    # ----- LogisticRegression (2,304 คอมโบ) -----\n",
    "    # C แบบละเอียด (log-space) ครอบคลุมกว้างมาก\n",
    "    \"clf__C\": list(np.logspace(-4, 3, 24)),   # 24 ค่า ตั้งแต่ 1e-4 ถึง 1e3\n",
    "    # ลด tol ให้เล็กลงเพื่อยืดเวลา iterate\n",
    "    \"clf__tol\": [1e-3, 1e-4, 1e-5, 1e-6],     # 4 ค่า\n",
    "    # เพิ่มรอบสูง เพื่อกันหลุดหยุดเร็ว\n",
    "    \"clf__max_iter\": [5000, 10000, 20000],    # 3 ค่า\n",
    "    # ถ่วง class\n",
    "    \"clf__class_weight\": [None, \"balanced\"],  # 2 ค่า\n",
    "    # ลองมี/ไม่มี intercept\n",
    "    \"clf__fit_intercept\": [True, False],      # 2 ค่า\n",
    "    # warm_start มี/ไม่มี (แม้ grid แต่ละตัวเป็น estimator ใหม่ ก็ยังเพิ่มเวลา/คอมโบได้)\n",
    "    \"clf__warm_start\": [True, False],         # 2 ค่า\n",
    "}\n",
    "\n",
    "best_lr = run_grid_search(lr_pipe, grid_lr)"
   ],
   "id": "8ee00c3a2c424384",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pipeline ที่ fix ค่า hyperparameters ตาม best params\n",
    "rf_best = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        class_weight=None,\n",
    "        max_depth=10,\n",
    "        max_features=\"sqrt\",\n",
    "        min_samples_leaf=6,\n",
    "        min_samples_split=2,\n",
    "        n_estimators=600\n",
    "    ))\n",
    "])\n",
    "\n",
    "# เทรนโมเดล\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "# ถ้าอยากดูผล\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", (y_pred == y_test).mean())\n",
    "\n",
    "joblib.dump(rf_best, 'models/best_rf_model.joblib')"
   ],
   "id": "6808dc4ef698fe32",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
